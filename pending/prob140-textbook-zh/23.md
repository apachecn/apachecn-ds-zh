# 23. 联合正态随机变量

共同正态随机变量高尔顿对椭圆散布图的观测成为多元回归的基础，是数据分析中最常用的方法之一。多元回归及其现代变体的推论通常是基于多元回归的

## 23.1 随机向量

向量值随机变量，或者更简单地说，随机向量，是在相同空间中定义的随机变量的列表。我们把它看做一个列。
$$
\mathbf{X} ~ = ~ 
\begin{bmatrix}
X_1 \\
X_2 \\
\vdots \\
X_n
\end{bmatrix}
$$
为了便于显示,我们有时会写
$$
\mathbf{X} = [X_1 X_2 \ldots X_n]^T
$$

$$
\mathbf{M}^T
$$

是相对于符号M矩阵的转置. X的平均向量
$$
\boldsymbol{\mu} = [\mu_1 ~ \mu_2 ~ \ldots ~ \mu_n]^T
$$

$$
当\mu_i = E(X_i)
$$

。X是
$$
n \times n
$$
矩阵的协方差矩阵Σ的第(i, j)元素是
$$
Cov(X_i, X_j)
$$
。Σ的第i个对角元素是
$$
X_i
$$
的方差。由于协方差的对称性，矩阵是对称的。



### 线性变换:均值向量

令A为
$$
m \times n
$$
的数值矩阵，b为
$$
m \times 1
$$
数值向量。考虑
$$
m \times 1
$$
随机向量Y=AX+b。Y的第i个元素是
$$
Y_i ~ = ~ \mathbf{A}_{i*}\mathbf{X} + \mathbf{b}(i)
$$
其中
$$
\mathbf{A}_{i*}
$$
是A的第i行，b(i)是b的第i个元素。
$$
Y_i ~ = ~ a_{i1}X_1 + a_{i2}X_2 + \cdots + a_{in}X_n + b_i
$$
其中
$$
a_{ij}
$$
是A的(i,j)项，
$$
b_i = \mathbf{b}(i)
$$
因此
$$
Y_i
$$
是一个对于元素X的线性组合，因此线性的期望为,
$$
E(Y_i) ~ = ~ \mathbf{A}_{i*} \boldsymbol{\mu} + \mathbf{b}(i)
$$
让
$$
μ_Y
$$
 作为y的平均向量, 通过上面的计算中, 
$$
\boldsymbol{\mu}_\mathbf{Y} ~ = ~ \mathbf{A} \boldsymbol{\mu} + \mathbf{b}
$$


### 线性变换:协方差矩阵

$$
Cov(Y_i, Y_j)
$$

可以用协方差的双线性度来计算。
$$
\begin{align*}
Cov(Y_i, Y_j) ~ &= ~ Cov(\mathbf{A}_{i*}\mathbf{X}, \mathbf{A}_{j*}\mathbf{X}) \\
&= ~ Cov\big{(} \sum_{k=1}^n a_{ik}X_k, \sum_{l=1}^n a_{jl}X_l \big{)} \\
&= ~ \sum_{k=1}^n\sum_{l=1}^n a_{ik}a_{jl}Cov(X_k, X_l) \\
&= ~ \sum_{k=1}^n\sum_{l=1}^n a_{ik}Cov(X_k, X_l)t_{lj} ~~~~~ \text{where } t_{lj} = \mathbf{A}^T(l, j) \\
\end{align*}
$$
 (l, j)这是
$$
\mathbf{A}\boldsymbol{\Sigma}\mathbf{A}^T
$$
的元素。如果
$$
Σ_Y
$$
表示协方差矩阵Y,那么
$$
\boldsymbol{\Sigma}_\mathbf{Y} ~ = ~ \mathbf{A} \boldsymbol{\Sigma} \mathbf{A}^T
$$


### 矩阵Σ上的限制

我们知道Σ必须对称,所有主对角线上的元素必须是非负数。同时,无论什么,
$$
Σ_Y
$$
所有必须的对角元素非负时的方差的元素Y
$$
Σ_Y
$$
的公式

也就是说
$$
\mathbf{a}^T \boldsymbol{\Sigma} \mathbf{a} ~ \ge ~ 0 ~~~~ \text{for all } n\times 1 \text{ vectors } \mathbf{a}
$$
因为
$$
\mathbf{a} \boldsymbol{\Sigma} \mathbf{a}^T
$$

是一个标量，因此等于它的转置。

也就是说,Σ必须半正定。通常，我们会用正定协方差矩阵

因为如果
$$
\mathbf{a} \boldsymbol{\Sigma} \mathbf{a}^T = 0
$$
X的一些元素的线性组合是恒定的。因此，你可以把一些元素写成其他元素的线性组合，然后研究一个简化的元素集。




## 23.2 多元正态分布

让Σ正定矩阵。一个n维随机向量Xμ多元正态分布的均值向量和协方差矩阵Σ如果X的元素的联合密度是由
$$
f_\mathbf{X}(\mathbf{x}) ~ = ~ \frac{1}{(\sqrt{2\pi})^n \sqrt{\det(\boldsymbol{\Sigma})} }
\exp\big{(}-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})\big{)}
$$
我们说X的元素是联合正态的或者联合高斯的。



当n=1时，应检查公式是否正确。在这种情况下
$$
\boldsymbol{\Sigma} = [\sigma^2]
$$
是一个标量。它是一个数字，不是一个更大的矩阵;它的行列式是它自己;它的逆矩阵是
$$
1/\sigma^2
$$
。另外,
$$
\mathbf{x} = x
$$
和
$$
\boldsymbol{\mu} = \mu
$$
只是数字。上面的公式中减少了熟悉的正常与均值μ和方差
$$
\sigma^2
$$
密度函数。



当X的元素是标准法线时，你也应该检查公式是否正确。在这种情况下μ= 0和
$$
\boldsymbol{\Sigma} = \mathbf{I}_n
$$
n维的单位矩阵。



在实验室里，你详细地研究了多元正态关节密度函数，从两个独立的标准正态分量组成的Z开始，然后进行线性组合。结果表明，所有的多元正态随机变量都可以用这种方法生成。事实上，对于多元正态分布的随机向量X有三个有用的等价定义。



**定义1**:X具有上述的关节密度。



**定义2**:X=AZ+b对于某个i i d标准法向量Z，一个可逆的A，和一个列向量b。



**定义3**:X的每个元素的线性组合都是正态分布。



在本节的最后，有一份关于建立相等关系的说明。有些地方很难。只要接受它们是正确的，让我们检查一下分布的性质。



理解多元法向量的关键是定义2:每个多元法向量是i.i.d标准法向量的线性变换。我们看看密度的定义2是什么。



### 二次形式

密度的形状是由二次型
$$
\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})
$$
。等值面为椭球体;在二维空间中，这些是你们在实验室里看到的椭圆。



这是与
$$
Cov(X_1, X_2) = 0.8
$$
共同法向的标准正态变量
$$
X_1
$$
和
$$
X_2
$$
的联合密度面。调用Plot_bivariate_normal(mu, cov)，其中均值向量mu是一个列表，协方差矩阵是一个指定行的列表列表。

```python
mu = [0, 0]
cov = [[1, 0.8], [0.8, 1]]
Plot_bivariate_normal(mu, cov)
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-2-0.png?raw=true)

注意椭圆的轮廓，并且概率集中在一条直线周围。



在二维以上的情况下，我们不能再画出节理密度面。在三维空间中，我们可以根据多元正态关节密度进行i.i.d.绘制，并绘制结果点。这是一个关于1000个标准正态变量X1,X2和X3的经验分布的例子，它们与
$$
Cov(X_1, X_2) = 0.6
$$
, 
$$
Cov(X_1, X_3) = 0.5
$$
, 
$$
Cov(X_2,X_3)=0.2
$$
共同正态。注意椭圆云。



调用为`Scatter_multivariate_normal(mu, cov, n)`，其中n是要生成的点数。函数检查指定的矩阵是否是正半定的。

```python
mu2 = [0, 0, 0]
cov2 = [[1, 0.6, 0.5], [0.6, 1, 0.2], [0.5, 0.2, 1]]
Scatter_multivariate_normal(mu2, cov2, 1000)
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-2-1.png?raw=true)

为了看到二次形式是如何产生的，让X是多元正态的。根据定义2,X=AZ+b对于某个可逆的A和向量b，以及某个i.i.d标准法向量Z。



通过边值的乘法，Z的关节密度为
$$
f(\mathbf{z}) ~ = ~ \frac{1}{(\sqrt{2\pi})^n} \exp\big{(}-\frac{1}{2}(z_1^2 + z_2^2 + \cdots + z_n^2)\big{)} ~ = ~ \frac{1}{(\sqrt{2\pi})^n }
\exp\big{(}-\frac{1}{2}\mathbf{z}^T\mathbf{z}\big{)}
$$
x在x=Az+b的线性变换下的原像是
$$
\mathbf{z} ~ = ~ \mathbf{A}^{-1}(\mathbf{x} - \mathbf{b})
$$
通过变量的变化X的密度的二次形式是
$$
\frac{1}{2}\mathbf{z}^T\mathbf{z} ~ = ~ 
\frac{1}{2} (\mathbf{x} - \mathbf{b})^T (\mathbf{A}^{-1})^T \mathbf{A}^{-1}(\mathbf{x} - \mathbf{b}) ~ = ~
\frac{1}{2} (\mathbf{x} - \mathbf{b})^T (\mathbf{AA}^T)^{-1} (\mathbf{x} - \mathbf{b})
$$
让
$$
μ_X
$$
均值向量X,因为X = AZ + b,我们有
$$
μ_X = b
$$
。

Z的协方差矩阵是
$$
\mathbf{I}_n
$$
。X的协方差矩阵是
$$
\boldsymbol{\Sigma}_\mathbf{X} ~ = ~ \mathbf{A} \mathbf{I}_n \mathbf{A}^T ~ = ~ \mathbf{A} \mathbf{A}^T
$$
所以X的密度的二次形式变成了
$$
\frac{1}{2} (\mathbf{x} - \mathbf{\mu_X})^T \boldsymbol{\Sigma}_\mathbf{X}^{-1} (\mathbf{x} - \mathbf{\mu_X})
$$

### 积分常数

通过变量的线性变化，X的密度为
$$
f_\mathbf{X}(\mathbf{x}) ~ = ~ f(\mathbf{z}) \cdot \frac{1}{s}
$$
其中z是x的原像，s是由变换后的单位向量构成的平行平面的体积。也就是说
$$
s = \|\det(\mathbf{A})\|
$$
。现在
$$
\det(\boldsymbol{\Sigma}_\mathbf{X}) ~ = ~ \det(\mathbf{AA}^T) ~ = ~ (\det(\mathbf{A}))^2
$$
因此X的密度的积分常数是
$$
\frac{1}{(\sqrt{2\pi})^n \sqrt{\det(\boldsymbol{\Sigma}_\mathbf{X})} }
$$
我们已经展示了关节密度函数是如何产生的以及它的各个部分代表了什么。在这个过程中，我们证明了定义2包含定义1。现在我们来证明这三个定义是等价的。



### 等值

这里有一些指标，如何看到这三个定义的等价。其中一块不容易确定。



定义2是多元法线性质的核心。我们将尝试看看为什么它等价于其他两个定义。



我们已经知道定义2意味着定义1。



看到定义1意味着定义2,它可以帮助记住一个正定矩阵Σ可以分解为一些下三角
$$
\boldsymbol{\Sigma} = \mathbf{AA}^T
$$
,只有积极的在其对角元素,因此是可逆的。这叫做切列斯基分解。设置
$$
\mathbf{Z} = \mathbf{A}^{-1}(\mathbf{X} - \boldsymbol{\mu})
$$
,定义1意味着定义2。



定义1和2是等价的。



你们已经知道独立正规变量的线性组合是正规的。如果X是i.i.d.标准正态变量Z的线性变换，那么X的任何元素的线性组合也是Z的元素的线性组合，因此是正态的。这意味着定义2意味着定义3。



定义3意味着定义2需要一些数学运算。多重矩母函数是一种解释为什么结果是正确的方法，如果我们接受矩广义函数决定分布，但我们不会在这里讨论。



## 线性组合

假设X是多元正态与平均向量Σμ和协方差矩阵。定义3说所有X的元素的线性组合也是正态的。这使得许多计算变得简单明了。这是一个二维的例子。



### 金额和差异

让
$$
\mathbf{X} = [X_1 ~ X_2]^T
$$
 二元正态分布平均向量
$$
\boldsymbol{\mu} = [\mu_1 ~ \mu_2]^T
$$
和协方差矩阵Σ。



然后和
$$
S = X_1 + X_2
$$
的正态分布均值
$$
μ_1 +μ_2
$$
和方差
$$
Var(S) ~ = ~ Var(X_1) + Var(X_2) + 2Cov(X_1, X_2)
$$
你可以根据Σ计算。


$$
D = X_1−X_2
$$
的区别有正态分布意味着
$$
μ_1−μ_2
$$
和方差
$$
Var(D) ~ = ~ Var(X_1) + Var(X_2) - 2Cov(X_1, X_2)
$$
不管X的元素的线性组合是什么，它的分布都是正态的。确定的参数分布,计算出均值和方差的均值和方差使用属性,然后找到必要的组件X均值向量和协方差矩阵的均值和方差,你都将发现使用正常的概率曲线和往常一样。

### 线性组合的联合分布

定义2表明有限个X的线性组合的联合分布是多元正态的。在上面的例子中，不仅S和D都是正态分布，S和D的联合分布也是二元正态分布。在上面的计算中，我们找到了均值向量和协方差矩阵中除一个元素外的所有元素。剩下的元素是
$$
Cov(S, D) ~ = ~ Cov(X_1 + X_2, X_1 - X_2) ~ = ~ Var(X_1) - Var(X_2)
$$
通过协方差的双线性和对称性。

### 临界

每一个Xi都是X元素的线性组合:在i处的系数是1，在其它地方的系数是0。每个Xi都是正态分布。这个正态分布的参数可以从均值向量和协方差矩阵中读出:
$$
E(X_i) = \boldsymbol{\mu}(i)
$$

$$
Var(X_i) = \boldsymbol{\Sigma}(i, i)
$$
但请注意:事实并非如此。如果一个随机向量的所有边都是正态的，则联合分布不必是多元正态的。

### 一个发人警醒的故事

下面的单元格显示了一个有趣数据集的经验联合分布和边缘分布。请阅读每个单元格顶部的注释，以查看正在计算和显示的内容。

```python
# Generate 100,000 iid standard normal points

x = stats.norm.rvs(size=100000)
y = stats.norm.rvs(size=100000)
t = Table().with_column(
    'X', x,
    'Y', y
)
```

```python
# Select just those where both elements have the same sign

new = t.where(t.column(0) * t.column(1) > 0)
```

```python
# The restricted pairs are not jointly normal;
# that shape isn't an ellipse

new.scatter(0, 1)
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-3-1.png?raw=true)

```python
# Empirical distribution of horizontal coordinate

new.hist(0, bins=25, ec='w')
plt.xticks(np.arange(-5, 6));
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-3-2.png?raw=true)

```python
# Empirical distribution of vertical coordinate

new.hist(1, bins=25, ec='w')
plt.xticks(np.arange(-5, 6));
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-3-3.png?raw=true)

两个边值都是正态的，但联合分布远不是二元正态的。



为了得到这些变量的关节密度的公式，从两个i.i.d.标准法线的圆对称关节密度开始，并将其限制在象限1和3。这样就少了原来曲面下一半的体积，所以要记住乘以2使新曲面下的总体积等于1。

```python
def new_density(x,y):
    if x*y > 0:
        return 1/np.pi * np.exp(-0.5*(x**2 + y**2))
    else:
        return 0

Plot_3d((-4, 4), (-4, 4), new_density, rstride=4, cstride=5)
```

![](https://github.com/mahaoyang/prob140-textbook-zh/blob/mastimg/23-3-4.png?raw=true)



## 23.4 独立性

如果X是相互独立的元素,那么
$$
Cov(X_i, X_j) = 0
$$
对于所有 i≠j, 因此协方差矩阵Σ是一个对角矩阵,它的第i个对角线元素是
$$
Var (X_i)
$$
。



另一方面，零协方差并不意味着相互独立，两两独立并不意味着相互独立。但是多元正态分布是一个很好的分布:



如果X是多变量正态分布，且其各元素两两不相关，即
$$
Cov(X_i,X_j)=0
$$
对于所有i≠j，则X各元素相互独立。



也就是说，**多元正态随机变量是独立的当且仅当它们不相关时**。



这是很容易看到的形式的密度X如果Σ是一个对角矩阵那么
$$
\boldsymbol{\Sigma}^{-1}
$$
。第i个对角元素的
$$
\boldsymbol{\Sigma}^{-1}=1/\sigma_i^2,当\sigma_i^2 = Var(X_i)
$$
。所以
$$
(\mathbf{x} - \boldsymbol{\mu})\boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) ~ = ~ \sum_{i=1}^n \frac{(x_i - \boldsymbol{\mu}(i))^2}{\sigma_i^2}
$$

$$
\exp\big{(} -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})\boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \big{)} ~ = ~ \prod_{i=1}^n \exp\big{(}-\frac{1}{2} \big{(}\frac{x_i - \boldsymbol{\mu}(i)}{\sigma_i}\big{)}^2\big{)}
$$

在积分常数,
$$
\det(\boldsymbol{\Sigma}) = \sigma_1^2 \sigma_2^2 \cdots \sigma_n^2
$$
。



因此X的密度是边际法向密度的乘积。

### 回顾一下求和以及求差

令
$$
\mathbf{X} = [X_1, X_2]^T
$$
不存在二元正态分布。
$$
令S=X_1+X_2, D=X_1 - X_2
$$
。我们知道S和D是二元正态分布
$$
Cov(S, D) ~ = ~ Var(X_1) - Var(X_2)
$$
如果
$$
X_1
$$
和
$$
X_2
$$
有相同的方差，那么S和D是不相关的，因此也与我们刚才证明的无关。例如，两个随机变量的和和差是独立的。
